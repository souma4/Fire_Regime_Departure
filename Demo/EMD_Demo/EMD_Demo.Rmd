---
title: "EMD Demo"
author: "Jeffrey Chandler"
date: "`r Sys.Date()`"
output:
#  bookdown::word_document2:
#    fig_caption: true
#    reference_docx: style.docx
  bookdown::html_document2:
    theme: united
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
    fig_caption: true
    df_print: paged
    code_download: true
    code_folding: hide
    highlight: tango
    css: styles.css
    mathjax: "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"
fontfamily: Times
fontsize: 12pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r packages-data, results = "hide", warning = F, message = FALSE}
pkgs <- c("tidyverse", "emdist", "ggpattern", "transport", "FamilyRank",
          "Compositional", "philentropy", "MASS", "reshape2", "ggExtra", "terra",
          "viridisLite", "ggpubr", "palmerpenguins", "RColorBrewer")
invisible(lapply(pkgs, library, character.only = T))

penguin <- penguins %>% drop_na()
colors <- brewer.pal(9,"Set3")[c(1,3,6)]
```

# Problem motivation

We are explorers in the Southern Ocean. We are studying three different species of penguins, Adelie, Gentoo, and Chinstrap penguins. We can identify the species, however we are making a guidebook for visitors. We want to produce a key based on anatomy that requires the minimal amount of information. This also provides scientists some benefit because we may be able infer evolutionary relationships based on similarity (like the genetics work by [Schiebinger et al., 2019](https://www.cell.com/cell/fulltext/S0092-8674(19)30039-X?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS009286741930039X%3Fshowall%3Dtrue)). Let's take a look at one important trait between the penguins, bill length. First we should plot their density distributions to see if bill lengths differ between species.

```{r }
#setosaXversicolor <- filter(iris, Species == "setosa" | Species == "versicolor")
#versicolor <- filter(iris, Species == "versicolor")
#virginica <- filter(iris, Species == "virginica")


ggplot(penguin, aes(x = bill_length_mm, color = species))+
  geom_density(fill = NA, linewidth = 1.5)+
  scale_color_manual(values = colors)+
  xlab("Bill Length (mm)")+
  ylab("Density")+
  ggtitle("Bill Length Density plots by species")+
  theme_classic()

```

We can see that Adelie penguins have smaller bill lengths than Gentoo and Chinstrap penguins. However, how far away? This may be useful because people can indentify large differences between bill lengths, therefore would be able to identify the species. The first thing we could do is to simply find the difference between the means

```{r }
means <- penguin %>%
  group_by(species)%>%
  summarize(mean_bill_length = mean(bill_length_mm))

print(paste0("Adelie to Chinstrap Distance = ",
             means$mean_bill_length[which(means$species == "Adelie")] - means$mean_bill_length[which(means$species == "Chinstrap")]))

print(paste0("Adelie to Gentoo Distance = ",
             means$mean_bill_length[which(means$species == "Adelie")] - means$mean_bill_length[which(means$species == "Gentoo")]))

print(paste0("Chinstrap to Gentoo Distance = ",
             means$mean_bill_length[which(means$species == "Chinstrap")] - means$mean_bill_length[which(means$species == "Gentoo")]))
```
```{r }
means_df <- means %>% mutate(y = c(1,1,1))

means_df$y[3] <- 1+means$mean_bill_length[which(means$species == "Chinstrap")] - means$mean_bill_length[which(means$species == "Gentoo")]
means_df <- rbind(means_df, c("Adelie", means$mean_bill_length[1], means_df$y[3]))

means_df$mean_bill_length <- as.numeric(means_df$mean_bill_length)
means_df$y <- as.numeric(means_df$y)

segments_startx <- c(means_df$mean_bill_length[1], means_df$mean_bill_length[1], means_df$mean_bill_length[3])
segments_endx <- c(means_df$mean_bill_length[2], means_df$mean_bill_length[3], means_df$mean_bill_length[2])
segments_starty <-c(means_df$y[1], means_df$y[4], means_df$y[3])
segments_endy <- c(means_df$y[2], means_df$y[3], means_df$y[2])

segments <- data.frame(startx = segments_startx, endx = segments_endx,
                       starty = segments_starty, endy = segments_endy)

ggplot()+
  geom_segment(aes(x = startx, xend = endx, y = starty, yend = endy), data = segments,
               arrow = arrow(ends = "both"))+
  geom_point(aes(x = mean_bill_length, y = y, color = species), means_df, size = 4)+
  annotate("text", x = 42.5, y = 1.2, label = abs(round(means_df$mean_bill_length[1]-means_df$mean_bill_length[2],2)))+
  annotate("text", x = 42.5, y = 2, label = abs(round(means_df$mean_bill_length[4]-means_df$mean_bill_length[3],2)))+
  annotate("text", x = 47.5, y = 1.5, label = abs(round(means_df$mean_bill_length[2]-means_df$mean_bill_length[3],2)))+
  scale_color_manual(values = colors)+
  scale_y_continuous(limits = c(1,5),
                     breaks = c(1,2),
                     minor_breaks = NULL)+
labs(x = "Mean Length",
     y = "Distance between Gentoo and difference in Gentoo and Chinstrap") +
  theme_classic() +
  theme(axis.text.y = element_blank())
  
```

We can see that Adelie is smaller than Chinstrap and Gentoo, which are close to each other.

A problem is, however, we have uncertainty around that mean value. Afterall, if there's a a large variance, Adelie penguins may have the same bill length as some Chinstrap penguins. We can address this by measuring the distance in terms of the variance around the data. We can use Standard deviations to see bill length differences while controlling for that variation. However, how do we decide which standard deviation to choose from? We can choose from the "reference" species. Let's try that

```{r }
means <- penguin %>%
  group_by(species)%>%
  summarize(mean_bill_length = mean(bill_length_mm), sd_bill_length = sd(bill_length_mm))

print(paste0("Adelie to Chinstrap Distance = ",
             (means$mean_bill_length[which(means$species == "Adelie")] - means$mean_bill_length[which(means$species == "Chinstrap")])/means$sd_bill_length[which(means$species == "Adelie")]))

print(paste0("Adelie to Gentoo Distance = ",
             (means$mean_bill_length[which(means$species == "Adelie")] - means$mean_bill_length[which(means$species == "Gentoo")])/means$sd_bill_length[which(means$species == "Adelie")]))

print(paste0("Chinstrap to Gentoo Distance = ",
             (means$mean_bill_length[which(means$species == "Chinstrap")] - means$mean_bill_length[which(means$species == "Gentoo")])/means$sd_bill_length[which(means$species == "Chinstrap")]))
```
```{r }
means_df <- means %>% mutate( y = c(1,1,1), x = c(
                                                  means$mean_bill_length[1]/means$sd_bill_length[1],
                                                  means$mean_bill_length[2]/means$sd_bill_length[1],
                                                  means$mean_bill_length[3]/means$sd_bill_length[1]
))


means_df$y[3] <- 1+(means$mean_bill_length[which(means$species == "Chinstrap")] - means$mean_bill_length[which(means$species == "Gentoo")])/means$sd_bill_length[2]
means_df <- rbind(means_df, c("Adelie", means$mean_bill_length[1],means$sd_bill_length[1], means_df$y[3],means$mean_bill_length[1]/means$sd_bill_length[1]))

means_df$mean_bill_length <- as.numeric(means_df$mean_bill_length)
means_df$y <- as.numeric(means_df$y)
means_df$x <- as.numeric(means_df$x)

segments_startx <- c(means_df$x[1], means_df$x[1], means_df$x[2])
segments_endx <- c(means_df$x[2], means_df$x[3], means_df$x[3])
segments_starty <-c(means_df$y[1], means_df$y[4], means_df$y[2])
segments_endy <- c(means_df$y[2], means_df$y[3], means_df$y[3])

segments <- data.frame(startx = segments_startx, endx = segments_endx,
                       starty = segments_starty, endy = segments_endy)

plot_by_sd <- ggplot()+
  geom_segment(aes(x = startx, xend = endx, y = starty, yend = endy), data = segments,
               arrow = arrow(ends = "last"))+
  geom_point(aes(x = x, y = y, color = species), means_df, size = 4)+
  annotate("text", x = 16, y = 1.2, label = abs(round(means_df$x[1]-means_df$x[2],2)))+
  annotate("text", x = 16, y = .8, label = abs(round(means_df$x[4]-means_df$x[3],2)))+
  annotate("text", x = 18.3, y = 1.3, label = abs(round(means_df$y[3]-1,2)))+
  scale_color_manual(values = colors)+
  scale_y_continuous(limits = c(0,5),
                     breaks = c(.5,1),
                     minor_breaks = NULL)+
labs(x = "Mean SD Normalized by Adelie To all",
     y = "Mean SD Normalized by Chinstrap and Gentoo") +
  theme_classic() +
  theme(axis.text.y = element_blank())
plot_by_sd
  
```

Let's see what happens when we swap the order though

```{r }
print(paste0("Gentoo to Chinstrap Distance = ",
             (means$mean_bill_length[which(means$species == "Gentoo")] - means$mean_bill_length[which(means$species == "Chinstrap")])/means$sd_bill_length[which(means$species == "Gentoo")]))
```
```{r }
adj <- 13.5
segments <- data.frame(starty = means$mean_bill_length[3]/means$sd_bill_length[3]-adj, endy = means$mean_bill_length[2]/means$sd_bill_length[3]-adj,
               startx = 15, endx = 15)
plot_by_sd +
  geom_point(aes(x = c(15,15), y =c(means$mean_bill_length[3]/means$sd_bill_length[3], means$mean_bill_length[2]/means$sd_bill_length[3])-adj),  color = colors[c(2,3)], size = 3 )+
  geom_segment(aes(x = startx, xend = endx, y = starty, yend = endy), data = segments,
               arrow = arrow(ends = "last"))+
  annotate("text",x = 15.3, y = 1.9,label = abs(round((means$mean_bill_length[which(means$species == "Gentoo")] - means$mean_bill_length[which(means$species == "Chinstrap")])/means$sd_bill_length[which(means$species == "Gentoo")],2)))+
  scale_x_continuous(limits = c(14,19))
  
```

We get different values. That's frequently not a desirable characteristic in a distance measure because you now must care about the order in which you perform operations. One way we can get around this is by pooling the variance

```{r }
print(paste0("Adelie to Chinstrap Distance = ",
             (means$mean_bill_length[which(means$species == "Adelie")] - means$mean_bill_length[which(means$species == "Chinstrap")])/(means$sd_bill_length[which(means$species == "Adelie")]+ means$sd_bill_length[which(means$species == "Chinstrap")])))

print(paste0("Adelie to Gentoo Distance = ",
             (means$mean_bill_length[which(means$species == "Adelie")] - means$mean_bill_length[which(means$species == "Gentoo")])/(means$sd_bill_length[which(means$species == "Adelie")]+ means$sd_bill_length[which(means$species == "Gentoo")])))

print(paste0("Chinstrap to Gentoo Distance = ",
             (means$mean_bill_length[which(means$species == "Chinstrap")] - means$mean_bill_length[which(means$species == "Gentoo")])/(means$sd_bill_length[which(means$species == "Chinstrap")]+ means$sd_bill_length[which(means$species == "Gentoo")])))

print(paste0("Gentoo to Chinstrap Distance = ",
             (means$mean_bill_length[which(means$species == "Gentoo")] - means$mean_bill_length[which(means$species == "Chinstrap")])/(means$sd_bill_length[which(means$species == "Gentoo")] + means$sd_bill_length[which(means$species == "Chinstrap")])))
```

```{r }
means_df <- means %>% mutate( y = c(1,1,1), x = c(
                                                  means$mean_bill_length[1]/(means$sd_bill_length[1]+means$sd_bill_length[2]),
                                                  means$mean_bill_length[2]/(means$sd_bill_length[1]+means$sd_bill_length[2]),
                                                  means$mean_bill_length[3]/(means$sd_bill_length[1]+means$sd_bill_length[3])
))


means_df$y[3] <- 1+(means$mean_bill_length[which(means$species == "Chinstrap")] - means$mean_bill_length[which(means$species == "Gentoo")])/(means$sd_bill_length[2]+means$sd_bill_length[3])
means_df <- rbind(means_df, c("Adelie", means$mean_bill_length[1],means$sd_bill_length[1], means_df$y[3],means$mean_bill_length[1]/(means$sd_bill_length[1]+means$sd_bill_length[3])))

means_df$mean_bill_length <- as.numeric(means_df$mean_bill_length)
means_df$y <- as.numeric(means_df$y)
means_df$x <- as.numeric(means_df$x)

segments_startx <- c(means_df$x[1], means_df$x[4], means_df$x[2])
segments_endx <- c(means_df$x[2], means_df$x[3], means_df$x[3])
segments_starty <-c(means_df$y[1], means_df$y[4], means_df$y[2])
segments_endy <- c(means_df$y[2], means_df$y[3], means_df$y[3])

segments <- data.frame(startx = segments_startx, endx = segments_endx,
                       starty = segments_starty, endy = segments_endy)

plot_by_sd_pool <- ggplot()+
  geom_segment(aes(x = startx, xend = endx, y = starty, yend = endy), data = segments,
               arrow = arrow(ends = "both"))+
  geom_point(aes(x = x, y = y, color = species), means_df, size = 4)+
  annotate("text", x = 7, y = .8, label = abs(round(means_df$x[1]-means_df$x[2],2)))+
  annotate("text", x = 7, y = 1.4, label = abs(round(means_df$x[4]-means_df$x[3],2)))+
  annotate("text", x = 8.1, y = 1.3, label = abs(round(means_df$y[3]-1,2)))+
  scale_color_manual(values = colors)+
  scale_y_continuous(limits = c(0,3),
                     breaks = c(1,1.5),
                     minor_breaks = NULL)+
labs(x = "Mean SD Normalized by Adelie To all, pooled",
     y = "Mean SD Normalized by Chinstrap and Gentoo, pooled") +
  theme_classic() +
  theme(axis.text.y = element_blank())
plot_by_sd_pool
  
```

This corrects the problem of directionality while still incorporating the variance of the underlying distributions. The next step we can make is by controlling for the variance in the means. Right now we are just controlling for variance in the distributions. We can use our sample size of each penguin to calculate "standard error", the expected variation within our mean value. When we normalize by standard error, we need to square the standard error around each mean, then take the square root of that sum.

```{r }
means <- penguin %>%
  group_by(species)%>%
  summarize(counts = n(), mean_bill_length = mean(bill_length_mm), sd_bill_length = sd(bill_length_mm) )%>%
  mutate(se_bill_length = (sd_bill_length/sqrt(counts))^2)

print(paste0("Adelie to Chinstrap Distance = ",
             (means$mean_bill_length[which(means$species == "Adelie")] - means$mean_bill_length[which(means$species == "Chinstrap")])/sqrt(means$se_bill_length[which(means$species == "Adelie")]+ means$se_bill_length[which(means$species == "Chinstrap")])))

print(paste0("Adelie to Gentoo Distance = ",
             (means$mean_bill_length[which(means$species == "Adelie")] - means$mean_bill_length[which(means$species == "Gentoo")])/sqrt(means$se_bill_length[which(means$species == "Adelie")]+ means$se_bill_length[which(means$species == "Gentoo")])))

print(paste0("Chinstrap to Gentoo Distance = ",
             (means$mean_bill_length[which(means$species == "Chinstrap")] - means$mean_bill_length[which(means$species == "Gentoo")])/sqrt(means$se_bill_length[which(means$species == "Chinstrap")]+ means$se_bill_length[which(means$species == "Gentoo")])))

print(paste0("Gentoo to Chinstrap Distance = ",
             (means$mean_bill_length[which(means$species == "Gentoo")] - means$mean_bill_length[which(means$species == "Chinstrap")])/sqrt(means$se_bill_length[which(means$species == "Gentoo")] + means$se_bill_length[which(means$species == "Chinstrap")])))
```

```{r }
means_df <- means %>% mutate( y = c(1,1,1), x = c(
                                                  means$mean_bill_length[1]/sqrt(means$se_bill_length[1]+means$se_bill_length[2]),
                                                  means$mean_bill_length[2]/sqrt(means$se_bill_length[1]+means$se_bill_length[2]),
                                                  means$mean_bill_length[3]/sqrt(means$se_bill_length[1]+means$se_bill_length[3])
))


means_df$y[3] <- 1+(means$mean_bill_length[which(means$species == "Chinstrap")] - means$mean_bill_length[which(means$species == "Gentoo")])/sqrt(means$se_bill_length[2]+means$se_bill_length[3])
means_df <- rbind(means_df, c("Adelie",means$counts[1], means$mean_bill_length[1],means$sd_bill_length[1],means$se_bill_length[1], means_df$y[3],means$mean_bill_length[1]/sqrt(means$se_bill_length[1]+means$se_bill_length[3])))

means_df$mean_bill_length <- as.numeric(means_df$mean_bill_length)
means_df$y <- as.numeric(means_df$y)
means_df$x <- as.numeric(means_df$x)

segments_startx <- c(means_df$x[1], means_df$x[4], means_df$x[2])
segments_endx <- c(means_df$x[2], means_df$x[3], means_df$x[3])
segments_starty <-c(means_df$y[1], means_df$y[4], means_df$y[2])
segments_endy <- c(means_df$y[2], means_df$y[3], means_df$y[3])

segments <- data.frame(startx = segments_startx, endx = segments_endx,
                       starty = segments_starty, endy = segments_endy)

plot_by_se_pool <- ggplot()+
  geom_segment(aes(x = startx, xend = endx, y = starty, yend = endy), data = segments,
               arrow = arrow(ends = "both"))+
  geom_point(aes(x = x, y = y, color = species), means_df, size = 4)+
  annotate("text", x = 90, y = 1.3, label = abs(round(means_df$x[1]-means_df$x[2],2)))+
  annotate("text", x = 115, y = 3.1, label = abs(round(means_df$x[4]-means_df$x[3],2)))+
  annotate("text", x = 112, y = 1.2, label = abs(round(means_df$y[3]-1,2)))+
  scale_color_manual(values = colors)+
  scale_y_continuous(limits = c(0,10),
                     breaks = c(1,3),
                     minor_breaks = NULL)+
labs(x = "Mean SE Normalized by Adelie To all, pooled",
     y = "Mean SE Normalized by Chinstrap and Gentoo, pooled") +
  theme_classic() +
  theme(axis.text.y = element_blank())
plot_by_se_pool
  
```

Now we get distances that don't care about direction and incorporate the underlying variance of our known means. We can see that Adelie penguins are very different from Chinstrap and Gentoo penguins, which are quite similar to each other. This computation is actually the two sample T-statistic. We can check this by doing a t test in base R. Let's do Adelie to Chinstrap Penguins.

```{r }
ad <- penguin%>%filter(species == "Adelie")
chi <- penguin %>%filter(species == "Chinstrap")
ge <- penguin %>%filter(species == "Gentoo")
test <- t.test(ad$bill_length_mm,
       chi$bill_length_mm, var.equal = F)

print(paste0("the test statistic/ distance is : ",test$statistic))


```

We get the same result

This works well. However, implicit within the definitions of standard deviation and standard error are that the data, and their respective means, are normally distributed. Not all data sets are normally distributed. In fact, Gentoo penguins appear to be non-normal according to the Shapiro-Wilk normality test at .05 significance level. I will admit, Gentoo is normal enough that we shouldn't throw out the idea that it approximates a normal distribution. However, we should be aware that the data are not normal, and that our distance metric is not robust to non-normality.

```{r }
shapiro.test(ge$bill_length_mm)
qqnorm(ge$bill_length_mm, pch = 1, frame = FALSE)
qqline(ge$bill_length_mm, col = "steelblue", lwd = 2)
```

How can we measure distance when means may not accurately reflect our data?

# Intuition and Calculation of Earth Mover's Distance.

Let's take our problem and recontextualize it slightly. Instead of measuring from mean to mean, lets "move" one distribution to the next, as if we are moving earth from one pile to another. We can think of the actual computation for this using children's blocks. We have a wall with 12 blocks, 6 x 2. Let's build two 1 x 6 towers from that wall moving the fewest blocks in the most efficient way. Moving vertically has no cost, but moving laterally does. If we move one block laterally, it costs one. 

What is the effort required to make these moves using minimum effort?


```{r conceptual, , fig.width = 10, fig.height = 10}
knitr::include_graphics("Children_blocks_conceptual_model.jpg")
```

From this simple diagram we can deduce logically that we make eight moves, each with a cost of one, our "effort" was 8. The means in this case are exactly equal, yet we clearly have different structures. If we represent probability mass functions in this matter, we can do the same computation to see how distributions differ from each other. Let's apply this logic to the penguins dataset. First we need to discretize our data. I'm going to choose a binwidth of 0.05 (aka dx = 0.05).

```{r , warning=FALSE}
dx = 1
bins <- seq(32,60,dx)

bin_df <- data.frame(bin = bins)%>%
  mutate(index = row_number())

pen_disc <- penguin %>%
    mutate(index = cut(bill_length_mm, breaks = bins, labels = F, include.lowest = T)) %>%
    group_by(species,index) %>%
    summarise(n = n()) %>%
    mutate( rel = n/sum(n))%>% 
    right_join(bin_df,by = "index") %>%
    dplyr::select(bin, rel) %>%
    mutate(bin = ifelse(is.na(bin),0,bin)) %>%
  drop_na()
  
discrete_plot <- ggplot()+
  geom_col(aes(x = bin, y = rel, fill = species), pen_disc, position = "dodge")+
  scale_fill_manual(values = colors)+
  xlab("Bill Length (mm)")+
  ylab("Mass")+
  ggtitle("Bill Length Column plots by species")+
  theme_classic()
discrete_plot
```

This shows similar information as the density plots above, but now the data is discrete and we can track how much "mass" we move and where. Next lets model the costs of moving. This can be be performed by making a matrix of costs (C) where columns indicate "from" and rows indicate "to". so the cell index [4,2] would be the cost of moving any mass from 2 to 4. In this case, let's choose the standard euclidean distance (e.g. $abs(4-2) = 2$). See "[Cost Matrix Changes]" in the supplemental information). For illustrative simplicity, let's remove Chinstrap penguins so we only focus on one computation. Let's plot our distributions with a cost matrix from Adelie to Gentoo penguins.



```{r, echo = F, show.results = "hide"}
pen_disc_ad <- pen_disc%>%
  filter(species == "Adelie")%>%
ggplot( aes(x = bin, y = rel,))+
  geom_col(fill = colors[1])+
  
  scale_x_continuous(limits = c(32,60))+
  scale_fill_manual(values = colors[1])+

  theme_void()
# ggsave("sXv_disc_set.jpg", sXv_disc_set)
# ggsave("pen_disc_ad.jpg", pen_disc_ad)
pen_disc_ge <- pen_disc%>%
  filter(species == "Gentoo")%>%
  mutate(bin = -bin)%>%
ggplot( aes(x = bin, y = rel,))+
  geom_col(fill = colors[3])+
  coord_flip()+
  scale_fill_manual(values = colors[3])+
  scale_x_continuous(limits = c(-60,-32))+
  scale_y_reverse()+
  theme_void()
# ggsave("sXv_disc_ver.jpg", sXv_disc_ver)
  # ggsave("pen_disc_ge.jpg", pen_disc_ge)
empty <- ggplot() + theme_void()
```

```{r, show.results = "hide"}
n <- length(bins)
C <- matrix(nrow = n, ncol = n)
for(i in 1:n){
  for(j in 1:n){
    C[i,j] = sqrt((bins[i]-bins[j])^2)
  }
}
```

```{r, }
dimnames(C) <- list(x = bins, y = bins)
C_df <- melt(C, value.name = "intensity")

plot <- ggplot(C_df) +
  geom_raster(aes(x = x, y = -y, fill = intensity))+
  scale_fill_viridis_c()+
  scale_x_continuous(position = "top")+
  scale_y_continuous(breaks = c(-40,-50,-60),
                    labels = c(40,50,60))+
  labs(x = NULL,
       y = NULL,
    fill="Distance")+
  theme_classic()

# ggarrange(
#   empty, pen_disc_ad, 
#   pen_disc_ge, plot,
#   nrow = 2, ncol = 2,
#   widths = c(1,3),
#   heights = c(1,2)
#   
# )
```
```{r echo = F}
knitr::include_graphics("cost_mat_marginal.jpg")
```

Here we can see that the 1:1 line is 0. That makes sense because if we move from a place to the same place, we don't move at all. The highest costs are at the corners, where you move from the beginning of the range to the end of the range. Also note, this matrix is symmetric. Moving from 2 to 4 is equal to moving from 4 to 2.

The next step is to actually find the minimum effort to move from Adelie to Gentoo. While there are multiple ways of doing this (I discuss one in [Entropy Regularization]) we're going to use the standard and general approach. 

These types of problems --- those where we want to move "stuff" from one place to another given some goal and constraints (we want to perform it efficiently and without losing "earth") --- are suited for linear programming. We are going to use a basic linear program solver to move "earth" in such a way that minimizes the "effort" required to move from Adelie to Gentoo bill lengths. In math formulation this looks like

$$\text{effort} = <T,C> = (\sum_{i = 1}^{n}{ \sum_{j=1}^{m} {T_{ij} C_{ij}}})$$

$$\begin{array}{ll}
\text{minimize T,} &  <T, C>\\
\text{subject to} & T 1 = p, T^\top 1 = q, T \ge 0 \\
\end{array}$$

T is our transport map, C is the cost matrix, and i and j are the row and column indicies. 1 is a vector of 1s that form our contraints that all of Adelie ($p$) must move to all of Gentoo ($p$). Let's construct the linear system of equations and compute the transport map using the lpsolve::lp function.

```{r, echo = F, warning=FALSE}
bin_df <- data.frame(bin = bins)
Ap <- matrix(0,nrow = n, ncol = (n)*(n))
Aq <- matrix(0,nrow = n, ncol = (n)*(n))
z <- matrix(0,nrow=n,ncol=n)
z[,1] <- 1
#C <- vector(length = n)
#for(i in 1:n){
  
#    C[i] = sqrt((x[i]-x[1])^2)
  
#}


for(i in 1:(n)){
  Ap[i,] <- c(t(z))
  Aq[i,] <- c(z)
  z[,i] <- 0
  if(i == (n)){
    z[,1] <- 1
  }else{
  z[,i+1] <- 1
  }
}
dist1 <- pen_disc%>%
  filter(species == "Adelie")%>%ungroup() %>%
  left_join(bin_df,., by = "bin")%>%
  arrange(bin)%>%
  mutate(rel = ifelse(is.na(rel), 0, rel))%>%
  dplyr::select(all_of("rel"))%>%unlist()%>%unname()
dist2 <- pen_disc%>%
  filter(species == "Gentoo")%>%ungroup() %>%
  left_join(bin_df,., by = "bin")%>%
  arrange(bin)%>%
  mutate(rel = ifelse(is.na(rel), 0, rel))%>%
  dplyr::select(all_of("rel"))%>%unlist()%>%unname()
dist3 <- pen_disc%>%
  filter(species == "Chinstrap")%>%ungroup() %>%
  left_join(bin_df,., by = "bin")%>%
  arrange(bin)%>%
  mutate(rel = ifelse(is.na(rel), 0, rel))%>%
  dplyr::select(all_of("rel"))%>%unlist()%>%unname()
dist1 <- dist1
dist1 <- dist1/sum(dist1)
dist2 <- dist2
dist2 <- dist2/sum(dist2)
dist3 <- dist3
dist3 <- dist3/sum(dist3)
#Ap <- Ap[1:(n-1),]
B <- c(dist1,dist2)
A <- rbind(Ap,Aq)
dir <- rep("=",length(B))

solved <- invisible(lpSolve::lp("min",c(C),A, dir,B))
```
```{r eval = F}
solved <- invisible(lpSolve::lp("min",c(C),p, dir,q))
```

```{r, echo = F}


t <- t(matrix(solved$solution, nrow = n, ncol = n))
t_r <- rast(t)

cb <- viridis(256)
pax <- list(xat = c(8,18,28),xlabs = c(40,50,60),  yat = c(0,10,20), ylabs = c(60,50,40), side = c(2,3),
cex.axis = 3)
plg <- list(
  cex = 2.5
)
mar <- c(6,2,7.1,3)
# jpeg(file = "Transport_map.jpg", 1920, 1080)
#  plot(t_r, col = cb, mar = mar, pax = pax, plg = plg)
# dev.off()
```
```{r }
knitr::include_graphics("Transport_map_marginal.jpg")
```
Here we can see that we are moving mass from the 30-45 range of Adelie to the 40-60 range of Gentoo penguins. We can see where most of our mass is moved to, and that it corresponds to the peaks of Gentoo. Now we can calculate the total effort by multiplying C by T to generate an effort map, then adding every cell together to calculate the total effort.

Effort Map:

```{r }
t <- t(matrix(solved$solution, nrow = n, ncol = n)*C)
t_r <- rast(t)

cb <- viridis(256)
pax <- list(xat = c(8,18,28),xlabs = c(40,50,60),  yat = c(0,10,20), ylabs = c(60,50,40), side = c(2,3),
cex.axis = 3)
plg <- list(
  cex = 2.5
)
mar <- c(6,2,7.1,3)
 # jpeg(file = "Effort_map.jpg", 1920, 1080)
 #  plot(t_r, col = cb, mar = mar, pax = pax, plg = plg)
 # dev.off()

knitr::include_graphics("Effort_map_marginal.jpg")

```

Effort:

```{r}
calcTmap <- sum(solved$solution*c(C))
paste0("This is equal to sum(transport_map * C): ", calcTmap)
```

As a sanity check, lets check our manual calculation the lpsolve:lp function's "objective function" attribute that should be equivalent.

```{r}
calcObj <- solved$objval
paste0("The calculated solution is: ", calcObj)
```
We can see that lpsolve::lpobjval  provides the same value as calculating a transport map, multiplying by C, then summing every cell. With that information we can say that the effort from Adelie to Gentoo bill length is 8.77 (mm). If we compare that to our prior euclidean distance measure of 8.74, 8.77 is quite close but slightly different because the shapes of the distributions are slightly different. What we have just calculated is called the "Earth Mover's Distance" (EMD).

one nice thing about this metric is that R packages already exist. "transport" and "emdist" both can be used to calculate the EMD.
All we need is to create a matrix where the first column contains probabilities, the second column contains locations/bin values for those probabilities.

```{r}
dist_ad_df <- as.matrix(data.frame(weights = dist1, locations = bins))
dist_ge_df <- as.matrix(data.frame(weights = dist2, locations = bins))
dist_chi_df <- as.matrix(data.frame(weights = dist3, locations = bins))
```
```{r echo = F}
print("Adelie example matrix")
print(dist_ad_df)
print("Using emdist and transport")
```
```{r}
emdist_emd <-emdist::emd(dist_ad_df,dist_ge_df)
paste0("emdist package = ", emdist_emd)

transport_emd <-transport::wasserstein1d(bins,bins,1,dist1,dist2)
paste0("transport package = ", transport_emd)
```

Let's check the EMD's from Adelie to Chinstrap, and Chinstrap to Gentoo as a check

```{r echo = F}
transport_emd <-transport::wasserstein1d(bins,bins,1,dist1,dist3)
paste0("Adelie to Chinstrap = ", transport_emd)
transport_emd <-transport::wasserstein1d(bins,bins,1,dist2,dist3)
paste0("Chinstrap to Gentoo = ", transport_emd)
```
to jog our memory, here are the euclidean distances from earlier

```{r echo = F}

means <- penguin %>%
  group_by(species)%>%
  summarize(mean_bill_length = mean(bill_length_mm))

print(paste0("Adelie to Chinstrap Distance = ",
             means$mean_bill_length[which(means$species == "Adelie")] - means$mean_bill_length[which(means$species == "Chinstrap")]))

print(paste0("Adelie to Gentoo Distance = ",
             means$mean_bill_length[which(means$species == "Adelie")] - means$mean_bill_length[which(means$species == "Gentoo")]))

print(paste0("Chinstrap to Gentoo Distance = ",
             means$mean_bill_length[which(means$species == "Chinstrap")] - means$mean_bill_length[which(means$species == "Gentoo")]))


means_df <- means %>% mutate(y = c(1,1,1))

means_df$y[3] <- 1+means$mean_bill_length[which(means$species == "Chinstrap")] - means$mean_bill_length[which(means$species == "Gentoo")]
means_df <- rbind(means_df, c("Adelie", means$mean_bill_length[1], means_df$y[3]))

means_df$mean_bill_length <- as.numeric(means_df$mean_bill_length)
means_df$y <- as.numeric(means_df$y)

segments_startx <- c(means_df$mean_bill_length[1], means_df$mean_bill_length[1], means_df$mean_bill_length[3])
segments_endx <- c(means_df$mean_bill_length[2], means_df$mean_bill_length[3], means_df$mean_bill_length[2])
segments_starty <-c(means_df$y[1], means_df$y[4], means_df$y[3])
segments_endy <- c(means_df$y[2], means_df$y[3], means_df$y[2])

segments <- data.frame(startx = segments_startx, endx = segments_endx,
                       starty = segments_starty, endy = segments_endy)


ggplot()+
  geom_segment(aes(x = startx, xend = endx, y = starty, yend = endy), data = segments,
               arrow = arrow(ends = "both"))+
  geom_point(aes(x = mean_bill_length, y = y, color = species), means_df, size = 4)+
  annotate("text", x = 42.5, y = 1.2, label = abs(round(means_df$mean_bill_length[1]-means_df$mean_bill_length[2],2)))+
  annotate("text", x = 42.5, y = 2, label = abs(round(means_df$mean_bill_length[4]-means_df$mean_bill_length[3],2)))+
  annotate("text", x = 47.5, y = 1.5, label = abs(round(means_df$mean_bill_length[2]-means_df$mean_bill_length[3],2)))+
  scale_color_manual(values = colors)+
  scale_y_continuous(limits = c(1,5),
                     breaks = c(1,2),
                     minor_breaks = NULL)+
labs(x = "Mean Length",
     y = "Distance between Gentoo and difference in Gentoo and Chinstrap") +
  theme_classic() +
  theme(axis.text.y = element_blank())
```

Our EMDs are similar to the Euclidean distances, but not exactly because the distributions are not perfectly normal. These distance can be used to compare different groups in a more robust way. There is also room to further develop the metric to account for variance. The metric also works in multiple dimensions. A note on EMD in multiple dimensions, data should be converted to a gridded probability map or use the Compositional::mkde function to normalize the data by density.

$*$if you want to see what the transport cost looks like in 2D, or you want another resource to learn about Optimal transport, the resource at this link:  [A Short Introduction to Optimal Transport and Wasserstein Distance](http://alexhwilliams.info/itsneuronalblog/2020/10/09/optimal-transport/)

# 2D EMD

Let's demonstrate what 2D EMD looks like. We will use the penguins dataset again. We will use the bill and flipper lengths between Adelie and Gentoo penguins.

Bill and Flipper Length Scatter plots. 

```{r echo = F}
pen_2D <- penguin %>%
  ggplot(aes(x=bill_length_mm,y = flipper_length_mm, color = species))+
  geom_point()+
  scale_color_manual(values = colors)+
  xlab("Bill Length (mm)")+
  ylab("Flipper Length (mm)")+
  ggtitle("Scatter Plots between Bill and Flipper Length")+
  theme_classic()+
  theme(plot.title = element_text(size = 10))
ggMarginal(pen_2D,groupColour = T, groupFill = T, type = "density")
```

We will focus on Adelie to Gentoo for 2D EMD

```{r echo = F}
ad_2D <- penguin %>%filter(species == "Adelie") %>%
  dplyr::select(all_of(c("bill_length_mm", "flipper_length_mm","species")))
ge_2D <- penguin %>%filter(species == "Gentoo")  %>%
  dplyr::select(all_of(c("bill_length_mm", "flipper_length_mm","species")))

ad_kde <- data.frame(kde = mkde(as.matrix(ad_2D[,c(1,2)])))
#ad_kde$kde <- ad_kde$kde/sum(ad_kde$kde)
ge_kde <- data.frame(kde = mkde(as.matrix(ge_2D[,c(1,2)])))
#ge_kde$kde <- ge_kde$kde/sum(ge_kde$kde)
ad_kde$Model <- "Adelie"
ge_kde$Model <- "Gentoo"

df_kde <- rbind(ad_kde, ge_kde)
df_kde <- cbind(df_kde, penguin[which(penguin$species %in%c("Adelie","Gentoo")),c(3,5)])

# dist1_pp <- pp(as.matrix(ad_2D[,c(1,2)]))
# dist2_pp <- pp(as.matrix(chi_2D[,c(1,2)]))
# transport_solvedPp<- transport(dist1_pp,dist2_pp, p = 1)
# transport::plot.pp(dist1_pp,dist2_pp,transport_solvedPp, cex = 1, cols = colors)
```



Gridded density plots using a dx of 1 and dy of 5

```{r echo = F}
dxdy <- c(1,5)
df_kde_plot <- ggplot(df_kde, aes(x = bill_length_mm, y = flipper_length_mm, fill = Model))+
  geom_bin2d(aes(alpha = after_stat(count)),binwidth = dxdy)+
  guides(alpha = "none")+
  scale_fill_manual(values = colors[c(1,3)])+
  
  scale_alpha_continuous(range=c(0,1))+
  xlab("Bill Length (mm)")+
  ylab("Flipper Length (mm)")+
  theme_classic()

df_kde_plot

```
```{r echo = F}
bounds <- c(32,60,170,235)
x_min <- bounds[1]
x_max <-  bounds[2]
y_min <- bounds[3]
y_max <- bounds[4]

x_ticks <- seq(x_min,x_max,dxdy[1])
y_ticks <- seq(y_min,y_max,dxdy[2])


density_1 <- matrix(0, ncol = length(x_ticks), nrow = length(y_ticks))
density_2 <- density_1
#locs_array <- array(dim = c(length(y_ticks),length(x_ticks),2))



for(i in 1:(length(x_ticks)-1)){
  for(j in 1:(length(y_ticks)-1)){
    
    x_min <- x_ticks[i]
    x_max <- x_ticks[i+1]
    y_min <- y_ticks[j]
    y_max <- y_ticks[j+1]
    
    #locs_array[j,i,1] <- x_min
    #locs_array[j,i+1,1] <- x_max
    #locs_array[j,i,2] <- y_min
    #locs_array[j+1,i,2] <- y_max
    
    density_1[j,i] <-length(which(ad_2D$bill_length_mm>x_min & ad_2D$bill_length_mm < x_max & ad_2D$flipper_length_mm >y_min & ad_2D$flipper_length_mm<y_max))
    density_2[j,i] <- length(which(ge_2D$bill_length_mm>x_min & ge_2D$bill_length_mm < x_max & ge_2D$flipper_length_mm >y_min & ge_2D$flipper_length_mm<y_max))
  }
}
density_1_sum <- sum(density_1)
density_2_sum <- sum(density_2)

density_1 <- density_1/density_1_sum
density_2 <- density_2/density_2_sum

density_1_pg <- pgrid(density_1, boundary = bounds)#boundary sets the parameters for distance cost matrix
density_2_pg <- pgrid(density_2, boundary = bounds)

```

Transport can actually create a heatmap for 2D data of how much mass we are moving where.
Transport can also compute the EMD using weighted points, instead of a normalized grid, however it requires similar sample sizes.

Heatmap of moving Adelie to Gentoo in 2D with EMD values using different implementations

```{r echo = F}
# calc_2D_emd_transport <- transport::wasserstein(dist1_pp,dist2_pp, tplan = transport_solvedPp)
# paste0("The transport calculated EMD is: ", calc_2D_emd_transport)

emdist_dist1 <- ad_2D %>%
  mutate(weight = 1)%>% #setting weight to 1 because this is point based, points are not unequal in importance
  dplyr::select(all_of(c("weight","bill_length_mm","flipper_length_mm")))%>%as.matrix()
emdist_dist2<-ge_2D %>%
  mutate(weight = 1)%>%
  dplyr::select(all_of(c("weight","bill_length_mm","flipper_length_mm")))%>%as.matrix()

calc_2D_emd_emdist <-emd(emdist_dist1,emdist_dist2, max.iter = 1000)


```
```{r echo = F}
transport.solvedPg <- transport(density_1_pg, density_2_pg, p =1)
transport::plot.pgrid(density_1_pg,density_2_pg,transport.solvedPg, mass = "colour")
TC <- wasserstein(density_1_pg, density_2_pg, tplan = transport.solvedPg)
print(paste0("EMD using wasserstein() = ", TC))
TC <- emd2d(density_1,density_2,xdist=dxdy[1],ydist=dxdy[2])
print(paste0("EMD using emd2d() = ", TC))

TC <- emd(as.matrix(df_kde[which(df_kde$Model == "Adelie"),-2]), as.matrix(df_kde[which(df_kde$Model == "Gentoo"),-2]), max.iter = 1000)
print(paste0("EMD using emd() = ", TC))

paste0("The emdist calculated EMD with points set to weight = 1 is: ", calc_2D_emd_emdist)
```

# Supplemental
## EMD definitions

Earth Mover's Distance (EMD; A.K.A. 1-Wasserstein metric, Kantorovich distance, Mallows Distance, Ocean Mover's distance, Fortet--Mourier distance, or minimal L$_p$ distance) is the minimum energy required to move mass (or "earth") from a distribution P to a distribution Q. 


EMD is a special case of "Optimal Transport", specifically the "1-st wasserstein metric". The Wasserstein metric is defined as 
$$\mathcal{W}_{p}(P, Q) = (\begin{matrix}inf\\\gamma \in \Gamma (P, Q) \\\end{matrix} \mathbf{E}_{(x,y) \sim \gamma}d(x,y)^p)^{1/p}
$$
The function is defined over a $d x d$ dimension space, so if the two distributions are 1D, the function space is 2D. $P$ and $Q$ are probability density functions. $p$ is an exponential scaling factor (A.K.A. a finite-moment). EMD is when p = 1. inf can be read as the minimum (its technically an infimum). $\Gamma(P,Q)$ is all couplings of $P$ and $Q$. $\gamma$ is a joint probability measure whose marginals are $P$ and $Q$ on the first and second factors, in effect, constraining our joint density between the two distributions to be equivalent. $\mathbf{E}_{(x,y) \sim \gamma}d(x,y)$ is the  is the expected value of of all derivatives from P to Q. This problem can be set up  as a linear programming$^[1]$  problem for computation.

$^[1]$ Linear programming is solving linear systems of equations with constraints. It's usage in our case is to ensure all of the mass from P moves to Q, and that we are trying to minimize the cost of that operation.

$$\text{effort}= <T,C>^{1/p} = (\sum_{i = 1}^{n}{ \sum_{j=1}^{m} {T_{ij} C_{ij}}})^{1/p}$$

$$\begin{array}{ll}
\text{minimize T,} &  <T, C>\\
\text{subject to} & T 1 = p, T^\top 1 = q, T \ge 0 \\
\end{array}$$


$$\begin{align}
\sum \langle T, C \rangle &= \text{EMD} \\
\begin{bmatrix} 
1 \\ 
1^\top \\
\end{bmatrix} T &= \begin{bmatrix}
                    p \\
                    q \\
                \end{bmatrix} \\
\text{Solve for } T
\end{align}$$

Where T is a transport Matrix, C is the Cost Matrix of movement from $P$ to $Q^{[2]}$. $i$ and $j$ are the values within each matrix corresponding to a cost in C and a "move" in T. We minimize The transport plan by cost such that we don't add mass, which is what the "subject to" terms are performing. We can use a linear program solver to solve for the transport plan, and EMD is the sum of T*C. 

Optimal transport has been referred to as "the natural geometry for probability measures" ([Cuturi, 2019](https://www.youtube.com/watch?v=6iR1E6t1MMQ))




## Entropy Regularization

The calculation time for EMD scales poorly, however [Altschuler et al., 2019](https://arxiv.org/abs/1705.09634);  [Dvurechensky et al., 2019](https://arxiv.org/abs/1802.04367), and [CH 4 Peyr√© & Cuturi (2019)](http://dx.doi.org/10.1561/2200000073) have introduced the usage of regularizing $<T,C$ by shannon entropy of T 
$$\begin{array}{ll}
\text{minimize T,} &  <T, C> - \epsilon H(T)\\
\text{subject to} & T 1 = p, T^\top 1 = q, T \ge 0 \\
\end{array}$$
where \( \epsilon \) is a regularization penalty. $H(T) = -\sum_{ij}T_{ij}\text{ }log\text{ }T{ij}$ which is the shannon entropy. As \( \epsilon\rightarrow \infty \) the Transport plan approaches $p_iq_j$.  This logically makes the plan easier to solve for, especially with the [sinkhorn algorithm](http://arxiv.org/abs/1306.0895) The way we implement this is by subtracting off $\epsilon H(C)$ from C in our implementation. EMD is calculated by $<T*,C>$ where $T*$ is our transport plan calculated from regularized data.

```{r echo = F}

shannon_entropy <- function(t_vec){
  log_vec <- log(t_vec)
  log_vec[which(log_vec == -Inf)] <- 0
  return(-sum((t_vec*log_vec-1)))
}
regularize <- function(bins,dist1, dist2,epsilon, C){
  bin_df <- data.frame(bin = bins)
  n <- length(bins)
Ap <- matrix(0,nrow = n, ncol = (n)*(n))
Aq <- matrix(0,nrow = n, ncol = (n)*(n))
z <- matrix(0,nrow=n,ncol=n)
z[,1] <- 1
#C <- vector(length = n)
#for(i in 1:n){
  
#    C[i] = sqrt((x[i]-x[1])^2)
  
#}


for(i in 1:(n)){
  Ap[i,] <- c(t(z))
  Aq[i,] <- c(z)
  z[,i] <- 0
  if(i == (n)){
    z[,1] <- 1
  }else{
  z[,i+1] <- 1
  }
}


dist1 <- dist1
dist1 <- dist1/sum(dist1)
dist2 <- dist2
dist2 <- dist2/sum(dist2)

B <- c(dist1,dist2)
A <- rbind(Ap,Aq)

dir <- rep("=",length(B))

c_vec <- c(C)
c_vec <- c_vec-epsilon*shannon_entropy(c_vec)

solved <- invisible(lpSolve::lp("min",c_vec,A, dir,B))

t_mat <- t(matrix(solved$solution, nrow = n, ncol = n))
t_r <- rast(t_mat)
return(t_r)
}
calc_emd_regularize <- function(t_r,  C){
  t_mat <- as.matrix(t_r, wide = T)
  emd <- sum(t_mat*C)
  return(emd)
}
```

```{r echo = F, fig.height = 26, fig.width = 28,show.results = FALSE}
dist1 <- pen_disc%>%
  filter(species == "Adelie")%>%ungroup() %>%
  left_join(bin_df,., by = "bin")%>%
  arrange(bin)%>%
  mutate(rel = ifelse(is.na(rel), 0, rel))%>%
  dplyr::select(all_of("rel"))%>%unlist()%>%unname()
dist2 <- pen_disc%>%
  filter(species == "Gentoo")%>%ungroup() %>%
  left_join(bin_df,., by = "bin")%>%
  arrange(bin)%>%
  mutate(rel = ifelse(is.na(rel), 0, rel))%>%
  dplyr::select(all_of("rel"))%>%unlist()%>%unname()
#Ap <- Ap[1:(n-1),]

t_r_0000 <- regularize(bins, dist1, dist2, 0,C)
t_r_0001 <- regularize(bins, dist1, dist2, 0.001,C)
t_r_0010 <- regularize(bins, dist1, dist2, 0.01,C)
t_r_0100 <- regularize(bins, dist1, dist2, 0.1,C)
t_r_1000 <- regularize(bins, dist1, dist2, 1,C)
t_r_10000 <- regularize(bins, dist1, dist2, 10,C)


cb <- viridis(256)
pax <- list(xat = c(8,18,28),xlabs = c(40,50,60),  yat = c(0,10,20), ylabs = c(60,50,40), side = c(2,3),
cex.axis = 6)




# note, my current setup requires manually saving the figure. jpeg just would not cooperate and it became easier to just edit in an image editing software.

 # jpeg(file = "Transport_map.jpg", 1920, 1080)

# parameter <- par(mfrow = c(2,3), mar = c(5,5,20,3), oma = c(10,2,2,2),cex.axis = 5, cex.main = 8, cex.lab = 5, cex.sub = 6)
# 
# parameter <- plot(t_r_0000, col = cb, pax = pax, legend = FALSE)
# title(main = expression(paste(epsilon, "= 0")),
#       sub = paste0("EMD = ", round(calc_emd_regularize(t_r_0000,C), 2)), line = -1)
# 
# parameter <- plot(t_r_0001, col = cb, pax = pax, legend = FALSE)
# title(main = expression(paste(epsilon, "= 0.001")),
#       sub = paste0("EMD = ", round(calc_emd_regularize(t_r_0010,C), 2)), line = -1)
# 
# parameter <- plot(t_r_0010, col = cb, pax = pax, legend = FALSE)
# title(main = expression(paste(epsilon, "= 0.01")),
#       sub = paste0("EMD = ", round(calc_emd_regularize(t_r_0010,C), 2)), line = -1)
# 
# parameter <- plot(t_r_0100, col = cb, pax = pax, legend = FALSE)
# title(main = expression(paste(epsilon, "= 0.1")),
#       sub = paste0("EMD = ", round(calc_emd_regularize(t_r_0100,C), 2)), line = -1)
# 
# 
# parameter <- plot(t_r_1000, col = cb, pax = pax, legend = FALSE)
# title(main = expression(paste(epsilon, "= 1")),
#       sub = paste0("EMD = ", round(calc_emd_regularize(t_r_1000,C), 2)), line = -1)
# 
# 
# parameter <- plot(t_r_10000, col = cb, pax = pax, legend = FALSE)
# title(main = expression(paste(epsilon, "= 10")),
#       sub = paste0("EMD = ", round(calc_emd_regularize(t_r_10000,C), 2)), line = -1)

 # dev.off()
```

```{r }
knitr::include_graphics("Entropy_regularization_nicer.jpg")
```

## Analytical solutions
### Univariate case

 When working with univariate distributions you can compute analytical solutions. The [proof](http://arxiv.org/abs/1803.00567) is beyond the scope of this document however the formulation is let $P^{-1}(u) \text{ and } Q^{-1}(u)$ be the inverse CDF of our pdfs $p(x) \text{ and } q(x)$ where u is a quantile from 0 to 1. We can define the wasserstein metric to be $(\int_{0}^{1}|P^{-1}(u) -Q^{-1}(u)|^{p}du)^{1/p}$. If $p=1$ the formula can further reduce to $(\int_{-\infty}^{\infty}|P(x) -Q(x)|dx)$ where $P(x)\text{ and }Q(x)$ are the CDF's of pdfs $p(x) \text{ and }q(x)$. This is basically the absolute difference between CDF's. This process looks like the following images.
 
```{r }
x <- seq(-3,3,.1)
dx <- x[2]-x[1]
dist1 <- dnorm(x)
dist2 <- dnorm(x, .5, .25)


```

Normal PDFs

```{r, echo = F}
df_1 <- data.frame(factors = x, distribution1 = dist1, distribution2 = dist2)

df_1 <- df_1 %>%
  mutate(difference = distribution2-distribution1, absoluteDifference = abs(difference))

colors <- c("#E66100","#0C7BDC")
df_1_long <- df_1 %>%
  pivot_longer(c(distribution1, distribution2,), names_to = "distribution", values_to = "val")
df_1_long$distribution <- as.factor(df_1_long$distribution)
distribution1ToDistribution2Plot <- ggplot()+
  geom_line(data = df_1_long, aes(x=factors, y = val, color = distribution ),
                    alpha = .6, linewidth = 2)+
  
  labs(x="x", y = "Density")+
  scale_color_manual(name='',
                    labels = c("Distribution 1", "Distribution 2"),
                     values=colors)+
   
  theme_classic() +
  ggtitle("")
distribution1ToDistribution2Plot

```

Normal CDFs with shaded absolute differences

```{r echo = F}
 
 dist1_cdf <- pnorm(x)
dist2_cdf <- pnorm(x, .5, .25)
df_1 <- data.frame(factors = x, distribution1 = dist1_cdf, distribution2 = dist2_cdf)

df_1 <- df_1 %>%
  mutate(difference = distribution2-distribution1, absoluteDifference = abs(difference))
df_1_ribbon <- df_1 %>%
  mutate(
    ymax = pmax(distribution1, distribution2),
    ymin = pmin(distribution1, distribution2),
    fill = TRUE
  )
df_max_diff <- df_1_ribbon[which.max(df_1_ribbon$absoluteDifference),1:7]
colors <- c("#E66100","#0C7BDC")
df_1_long <- df_1 %>%
  pivot_longer(c(distribution1, distribution2,), names_to = "distribution", values_to = "val")
df_1_long$distribution <- as.factor(df_1_long$distribution)
distribution1ToDistribution2Plot <- ggplot()+
 geom_ribbon(data = df_1_ribbon, aes(factors, ymin = ymin, ymax = ymax),
  fill = "#4B0092", alpha = .5)+
  geom_line(data = df_1_long, aes(x=factors, y = val, color = distribution ),
                    alpha = .6, linewidth = 2)+
  geom_segment(aes(x = factors, xend= factors,
                   y = ymin, yend = ymax),
  data = df_max_diff,linewidth = 1, color = "black",
  arrow = arrow(length = unit(0.03, "npc"),ends = "both"), show.legend = F)+
  labs(x="x", y = "Cumulative Frequency")+
  guides(segment = "none")+
  scale_color_manual(name='',
                    labels = c("Distribution 1", "Distribution 2"),
                     values=colors)+
   
  theme_classic() +
  ggtitle("")
distribution1ToDistribution2Plot
```

The function of absolute differences

```{r echo = F}
ggplot(data = df_1, aes(x = factors, y = absoluteDifference))+
  geom_ribbon(aes(ymin=0, ymax = absoluteDifference),fill = "#D50101", alpha = .6)+    
  geom_line(linewidth = 1.5)+
      
  labs(x = "x", y = "Absolute Difference")+
  theme_classic()

```



EMD is equal to the indefinite integral of the absolute difference function (in this case, EMD is equal to `r wasserstein1d(x,x,1,dist1,dist2)`)

### Gaussian Case

If we are given two 2D multivariate normal distributions with means $(\mu_{1},\mu_{2})$ and  covariances $(\Sigma_{1},\Sigma_{2})$ we can compute and analytical second order (p = 2) Wasserstein distance with $(\text{||}\mu_1-\mu_2\text{||}_2^2+\mathfrak{B}(\Sigma_1,\Sigma_2)^2)^{1/2}$ where $\mathfrak{B}$ is the Bures metric on positive-definite matrices. The Bures metric is defined as $\mathfrak{B}(\Sigma_1, \Sigma_2)^2 = 2(1-\sqrt{F(\Sigma_1,\Sigma_2)})$. $F(\Sigma_1,\Sigma2)$ is the [Fidelity Function](https://en.wikipedia.org/wiki/Fidelity_of_quantum_states) defined as $F(\Sigma_1,\Sigma2) = [tr(\sqrt{\sqrt{\Sigma_1}\Sigma_2\sqrt{\Sigma_1}}]^2$

In the Univariate normal case, we can simplify the equation to \( ((\mu_1-\mu_2)^2+(\sigma_1-\sigma_2)^2)^{1/2} \). In the above example, that would be \( ((0-1)^2+(.5-.25)^2) = \) `r ((0-1)^2+(.5-.25)^2)^(1/2)`. Let's check with the transport::wasserstein1D package: `r transport::wasserstein1d(x,x,2,wa = dist1,dist2)`. That is close enough because the inverse CDF method is numerically approximated, and we are computing it on a discretized space, which both introduce some level of approximation. We can actually interpret this calculation as the Euclidean distance of the parameters in 2D, axis 1 = mean, and axis 2 = standard deviation.



```{r echo = F}
df_params <- data.frame(mean = c(0,.5), sd = c(1,.25), colors = as.factor(rev(colors)))

segments <- data.frame(startx = df_params$mean[1],endx = df_params$mean[2],
                       starty = df_params$sd[1], endy = df_params$sd[2])
ggplot()+
  geom_segment(aes(x = startx, xend = endx, y = starty, yend = endy), data = segments,
               arrow = arrow(ends = "last"))+
  geom_point( aes(x = mean, y = sd,color = colors),df_params, size = 3)+
  
  scale_x_continuous(limits = c(0,2))+
  scale_y_continuous(limits = c(0,2))+
  scale_color_manual(values = colors,
                     labels = c("Dist 1", "Dist 2"))+
  annotate("text",x=.3,y=.75,label = 1.03)+
  labs(x="Mean",
       y="SD")+
  
  theme_classic()+
theme(legend.title = element_blank())
```

## Cost Matrix Changes

In the Wasserstein formulation above, we find the pairwise distances from $x_i$ to $x_j$ proportional to p. In the linear programming step we make two changes.

1. We modify our cost matrix C. C is generally defined as $C_{ij} = \text{||}x_i - x_j\text{||}_2^p$ which is the p-th vector norm.

2. We modify our $\mathcal{W}(P,Q) = <T,C>$ to be $\mathcal{W}(P,Q) = (<T,C>)^{1/p}$

These two changes give us the general computational formula for the wasserstein metric to the p-th order.

## Kantorovich-Rubenstein duality

A property of the wasserstein definition is that because we are optimizing over a minimum, there can be a "dual" that optimizes over a complementary optimum. For the wasserstein metric, the "dual" is known as the "Kantrorovich-Rubenstein duality" and is mostly used in Wasserstein General Adversarial Networks (WGAN). The formula is

$$\begin{matrix}\text{sup}\\\phi \in L_1 (\mu),\psi \in L_1 (\nu) \\ \phi(x) +\psi(y) \leq c(x,y) \\\end{matrix} \int \phi d\mu + \int \psi d \nu
$$

where $\phi$ and $\psi$ are a coupled joint probability, $\mu$ and $\nu$ are equal to P and Q from our wasserstein definition above, and c is your cost over (x,y). This effectively swaps the constraints and objective in our linear program. The reason this is used in GANs is because they are commonly operating within a generated cost (from a prompt, or input) and need to map that onto a distribution to generate an image, rather than our example where we try to map a distribution onto a cost. *note, they train WGANs, in part, using the standard formulation.

## Wasserstein Barycenter

Let's reframe the initial problem. Instead of asking "how far is Adelie penguin bill length from Gentoo penguin bill length?" to "what distribution best represents all three penguins". This could be useful for assessing the average conditions, resource benefits, phenology, etc of the sampled penguins. The standard way of performing this would involve taking a simple average. The average (in black) is added to our discrete graph below. 

```{r echo = F}
colors <- brewer.pal(9,"Set3")[c(1,3,6, 4)]
ave_pen_disc <- pen_disc %>%
  group_by(bin)%>%
  summarize(avrel = sum(rel)/3)
  discrete_plot+
  geom_col(aes(x = bin, y = avrel), data = ave_pen_disc, alpha = .6, fill = colors[4])+
  theme_classic()

```

As we can see, it's a simple average. However, it's safe for us to qualitatively say that the simple average distribution does not represent the individual distributions it's trying to describe. It's only smoothing the total distribution. This means that we are going to integrate the effects of species or islands as unaccounted for random effects. The wasserstein barycenter attempts to correct this problem by computing the distribution that minimizes the wasserstein metric to all of the target distributions. This computes a representative distribution that requires the least amount of effort to transform into the target distributions.

Here is what an updated plot looks like with the wasserstein barycenter

```{r echo = F}
source("Sinkhorn_barycenter.R")
dist1 <- pen_disc%>%
  filter(species == "Adelie")%>%ungroup() %>%
  left_join(bin_df,., by = "bin")%>%
  arrange(bin)%>%
  mutate(rel = ifelse(is.na(rel), 0, rel))%>%
  dplyr::select(all_of("rel"))%>%unlist()%>%unname()
dist2 <- pen_disc%>%
  filter(species == "Gentoo")%>%ungroup() %>%
  left_join(bin_df,., by = "bin")%>%
  arrange(bin)%>%
  mutate(rel = ifelse(is.na(rel), 0, rel))%>%
  dplyr::select(all_of("rel"))%>%unlist()%>%unname()
dist3 <- pen_disc%>%
  filter(species == "Chinstrap")%>%ungroup() %>%
  left_join(bin_df,., by = "bin")%>%
  arrange(bin)%>%
  mutate(rel = ifelse(is.na(rel), 0, rel))%>%
  dplyr::select(all_of("rel"))%>%unlist()%>%unname()

A <-cbind(dist1,dist2,dist3)+1e-9
barycenter <- barycenter_sinkhorn(A, C, reg = 1, log = TRUE)

barycenter_df <- data.frame(species = "Barycenter", bin = bins, rel = barycenter$res)

full_df <- rbind(pen_disc, barycenter_df)


barycenter_pen_disc <- full_df %>%
  ggplot()+
  geom_col(aes(x = bin, y = rel, fill = species), position = "dodge",  alpha = .6)+
  scale_fill_manual(values = colors[c(1,4,2,3)])+
  theme_classic()+
  theme(legend.title = element_blank())+
  labs(x = "Bill Length (mm)", y = "Mass")
# ggsave("Wass_barycenter.jpg", barycenter_pen_disc, device = "jpg", width = 7, height = 6, units = "in")

```
```{r fig.height = 18, fig.width = 21, echo = F}
knitr::include_graphics("Wass_barycenter.jpg")
```

## Wasserstein Geodesic Principal Components Analysis (GPCA)

Understanding Wasserstein GPCA we need to understand multiple layers of advanced mathematics. I will refer to [Geodesic Regression](https://towardsdatascience.com/geodesic-regression-d0334de2d9d8) and [Principal Geodesic Analysis](https://towardsdatascience.com/principal-geodesic-analysis-2ec7ad1b2679) for you to read and get up to speed on how to conceptualize the foundations.